{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dheeraj62/Churn_Prediction/blob/main/Churn_Prediction_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FzYccB24irQ"
      },
      "source": [
        "# Project : Churn Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXP7NhdPQpxy"
      },
      "source": [
        "## Reading Files into Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDWO5w4jIiWL"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFxGyLx3L5IS"
      },
      "outputs": [],
      "source": [
        "#importing data\n",
        "data = pd.read_csv('churn_prediction.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPcIwT47NQX6"
      },
      "outputs": [],
      "source": [
        "#first 5 instances using \"head()\" function\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G5CwMDl2B_8"
      },
      "outputs": [],
      "source": [
        "#last 5 instances using \"tail()\" function\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Iy0lfDNNZ8U"
      },
      "outputs": [],
      "source": [
        "#finding out the shape of the data using \"shape\" variable: Output (rows, columns)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b75gSeumN50y"
      },
      "outputs": [],
      "source": [
        "#Printing all the columns present in data\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfZv5qTw4rm_"
      },
      "source": [
        "## Variable Identification and Typecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Us_uMgBnF_"
      },
      "outputs": [],
      "source": [
        "# A closer look at the data types present in the data\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAh9MfrhFlBE"
      },
      "source": [
        "There are a lot of variables visible at one, so let's narrow this down by looking **at one datatype at once**. We will start with int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLXc4D7n9GIP"
      },
      "source": [
        "### Integer Data Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79o3VLDo-UcA"
      },
      "outputs": [],
      "source": [
        "# Identifying variables with integer datatype\n",
        "data.dtypes[data.dtypes == 'int64']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yix8gagv-gwr"
      },
      "source": [
        "Summary:\n",
        "\n",
        "*    **Customer id** are a unique number assigned to customers. It is are **Okay as Integer**.\n",
        "\n",
        "*    **branch code** again represents different branches, therefore it should be **convereted to category**.\n",
        "\n",
        "*    **Age** and **Vintage** are also numbers and hence we are okay with them as integers.\n",
        "\n",
        "*    **customer_networth_category** is supposed to be an ordinal category, **should be converted to category**.\n",
        "\n",
        "*    **churn** : 1 represents the churn and 0 represents not churn. However, there is no comparison between these two categories. This **needs to be converted to category datatype**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjim6-_NDUOe"
      },
      "outputs": [],
      "source": [
        "# converting churn to category\n",
        "data['churn'] = data['churn'].astype('category')\n",
        "data['branch_code'] = data['branch_code'].astype('category')\n",
        "data['customer_nw_category'] = data['customer_nw_category'].astype('category')\n",
        "data.dtypes[data.dtypes == 'int64']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRSHTCVY9MSl"
      },
      "source": [
        "### Float Data Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4teLfjkzWbg"
      },
      "outputs": [],
      "source": [
        "# Identifying variables with float datatype\n",
        "data.dtypes[data.dtypes == 'float64']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-97-KADzlCu"
      },
      "source": [
        "Summary:\n",
        "\n",
        "*    **dependents** is expected to be a whole number. **Should be changed to integer type**\n",
        "\n",
        "*    **city** variable is also a unique code of a city represented by some interger number. **Should be converted to Category type**\n",
        "\n",
        "*    Rest of the variables like **credit, balance and debit** are best represented by the float variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElAZeyTjWIh2"
      },
      "outputs": [],
      "source": [
        "# converting \"dependents\" and \"city\" to their respective types\n",
        "data['dependents'] = data['dependents'].astype('Int64')\n",
        "data['city'] = data['city'].astype('category')\n",
        "\n",
        "# checking\n",
        "data[['dependents','city']].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGScFSc_8Rl"
      },
      "source": [
        "### Object Data Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ou3CLuI9DwS"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzLUCLSU_Hmk"
      },
      "source": [
        "*    **variables like 'gender', 'occupation' and 'last_transaction' are of type object**. This means that **Pandas was not able to recognise the datatype** of these three variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjOBy8qRaYfl"
      },
      "outputs": [],
      "source": [
        "# Manually checking object types\n",
        "data[['gender','occupation','last_transaction']].head(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KOeDE6Bdlo4"
      },
      "source": [
        "*    **gender** and **occupation** variables **belong to categorical data types**.\n",
        "*    **last_transaction** should be a  **datetime variable**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WweHyTD1B-Hi"
      },
      "outputs": [],
      "source": [
        "# typecasting \"gender\" and \"occupation\" to category type\n",
        "data['gender'] = data['gender'].astype('category')\n",
        "data['occupation'] = data['occupation'].astype('category')\n",
        "\n",
        "# checking\n",
        "data[['gender','occupation']].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL6utzZVCXzZ"
      },
      "source": [
        "### datetime Data Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUW8X9y0cls5"
      },
      "outputs": [],
      "source": [
        "# creating an instance(date) of DatetimeIndex class using \"last_transaction\"\n",
        "date = pd.DatetimeIndex(data['last_transaction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiDzZxipexc8"
      },
      "outputs": [],
      "source": [
        "# extracting new columns from \"last_transaction\"\n",
        "\n",
        "# last day of year when transaction was done\n",
        "data['doy_ls_tran'] = date.dayofyear\n",
        "\n",
        "# week of year when last transaction was done\n",
        "data['woy_ls_tran'] = date.weekofyear\n",
        "\n",
        "# month of year when last transaction was done\n",
        "data['moy_ls_tran'] = date.month\n",
        "\n",
        "# day of week when last transaction was done\n",
        "data['dow_ls_tran'] = date.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX959YsKk0ie"
      },
      "outputs": [],
      "source": [
        "# checking new extracted columns using datetime\n",
        "data[['last_transaction','doy_ls_tran','woy_ls_tran','moy_ls_tran','dow_ls_tran']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey6xOF4gqHu2"
      },
      "source": [
        "The first column is the complete date of the last transaction which was done by the any given customer.\n",
        "\n",
        "The next columns represent the day of year, week of year, month of year, day of week when the last transaction was done.\n",
        "\n",
        "**Breaking down the date variable** into these granular information will **help us in understand when the last transaction was done from different perspectives**. Now that we have extracted the essentials from the last_transaction variables, we will drop it from the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVGFEI5aynYs"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns = ['last_transaction'])\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PZEQUlXii1G"
      },
      "source": [
        "## Univariate Analysis: Numerical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O8cRBfvipvQ"
      },
      "outputs": [],
      "source": [
        "# Numerical datatypes\n",
        "data.select_dtypes(include=['int64','float64','Int64']).dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHPCzH5ujHGZ"
      },
      "outputs": [],
      "source": [
        "# seggregating variables into groups\n",
        "customer_details = ['customer_id','age','vintage']\n",
        "current_month = ['current_balance','current_month_credit','current_month_debit','current_month_balance']\n",
        "previous_month = ['previous_month_end_balance','previous_month_credit','previous_month_debit','previous_month_balance']\n",
        "previous_quarters = ['average_monthly_balance_prevQ','average_monthly_balance_prevQ2']\n",
        "transaction_date = ['doy_ls_tran','woy_ls_tran','moy_ls_tran','dow_ls_tran']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv_U-gn5jLhf"
      },
      "outputs": [],
      "source": [
        "# custom function for easy and efficient analysis of numerical univariate\n",
        "\n",
        "def UVA_numeric(data, var_group):\n",
        "  '''\n",
        "  Univariate_Analysis_numeric\n",
        "  takes a group of variables (INTEGER and FLOAT) and plot/print all the descriptives and properties along with KDE.\n",
        "\n",
        "  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it\n",
        "  '''\n",
        "\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,3), dpi = 100)\n",
        "  \n",
        "  #looping for each variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    \n",
        "    # calculating descriptives of variable\n",
        "    mini = data[i].min()\n",
        "    maxi = data[i].max()\n",
        "    ran = data[i].max()-data[i].min()\n",
        "    mean = data[i].mean()\n",
        "    median = data[i].median()\n",
        "    st_dev = data[i].std()\n",
        "    skew = data[i].skew()\n",
        "    kurt = data[i].kurtosis()\n",
        "\n",
        "    # calculating points of standard deviation\n",
        "    points = mean-st_dev, mean+st_dev\n",
        "\n",
        "    #Plotting the variable with every information\n",
        "    plt.subplot(1,size,j+1)\n",
        "    sns.kdeplot(data[i], shade=True)\n",
        "    sns.lineplot(points, [0,0], color = 'black', label = \"std_dev\")\n",
        "    sns.scatterplot([mini,maxi], [0,0], color = 'orange', label = \"min/max\")\n",
        "    sns.scatterplot([mean], [0], color = 'red', label = \"mean\")\n",
        "    sns.scatterplot([median], [0], color = 'blue', label = \"median\")\n",
        "    plt.xlabel('{}'.format(i), fontsize = 20)\n",
        "    plt.ylabel('density')\n",
        "    plt.title('std_dev = {}; kurtosis = {};\\nskew = {}; range = {}\\nmean = {}; median = {}'.format((round(points[0],2),round(points[1],2)),\n",
        "                                                                                                   round(kurt,2),\n",
        "                                                                                                   round(skew,2),\n",
        "                                                                                                   (round(mini,2),round(maxi,2),round(ran,2)),\n",
        "                                                                                                   round(mean,2),\n",
        "                                                                                                   round(median,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Pk32OwisyT"
      },
      "source": [
        "### customer_information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YFj4I-wprgH"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(data,customer_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD-3il2nJt10"
      },
      "source": [
        "**Summary of Customer_Information:**\n",
        "*    **customer_id**:\n",
        "     *    variable is **unique for every customer, Hence uniform** distribution.\n",
        "     * This variable **does not contribute any information**\n",
        "     * Can be eliminated from data\n",
        "\n",
        "*    **age**:\n",
        "    *    Median Age = 46\n",
        "    *    **Most customers age between 30 to 66**\n",
        "    *    skewness +0.33 : customer age is **negligibly biased towards younger age**\n",
        "    *    **kurtosis = -0.17**; very less likely to have extreme/outlier values.\n",
        "*    **vintage:**\n",
        "    *    Most customers joined between 2100 and 2650 days from the day of data extraction.\n",
        "    *    **skewness** -1.42 : this is left skewed, **vintage variable is significantly biased towards longer association of customers.**\n",
        "    *    **Kurtosis = 2.93**: Extreme values and Outliers are very likely to be present in vintage.\n",
        "\n",
        "**Things to Investigate Further down the road:**\n",
        "*    The batch of **high number of very Old Age customers** in age variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiC2VomvlWS5"
      },
      "source": [
        "### current_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blZU92hHk81s"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(data,current_month)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J8ixOBgnE1O"
      },
      "source": [
        "**Summary**\n",
        "*    Considering the kurtosis and skewness value  for all 4 of these plots. Outliers/Extreme values are obvious."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9TpJ38koJbh"
      },
      "source": [
        "\n",
        "**Need to Remove Outliers to visulaise these plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvlh4yl1l5Tr"
      },
      "outputs": [],
      "source": [
        "# standard deviation factor\n",
        "factor = 3\n",
        "\n",
        "# copying current_month\n",
        "cm_data = data[current_month]\n",
        "\n",
        "# filtering using standard deviation (not considering obseravtions > 3* standard deviation)\n",
        "cm_data = cm_data[cm_data['current_balance'] < factor*cm_data['current_balance'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_credit'] < factor*cm_data['current_month_credit'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_debit'] < factor*cm_data['current_month_debit'].std()]\n",
        "cm_data = cm_data[cm_data['current_month_balance'] < factor*cm_data['current_month_balance'].std()]\n",
        "\n",
        "# checking how many points removed\n",
        "len(data), len(cm_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7eIx4invp0g"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(cm_data,current_month)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5T-Ldo0mLuJ"
      },
      "source": [
        "**Summary of current_month**\n",
        "*    After Removing extreme/outliers, plots are still very skewed.\n",
        "\n",
        "**Things to investigate further down**\n",
        "1.    **Is there thete any common trait/relation between the customers who are performing high transaction credit/debits?**\n",
        "2.    **Customers who are performinng high amount of transactions, are they doinng it every month?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ygh55Zok6v"
      },
      "source": [
        "### previous_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjXX4cApwmc4"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(data,previous_month)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNBUxvviqVGj"
      },
      "source": [
        "**Summary of previous_month**\n",
        "*    This looks very similar to current_month. Most of the customers perform low amount transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFQ4BEyKrLkR"
      },
      "source": [
        "### previous_quarters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sUZY9X7owHI"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(data,previous_quarters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTazVPaBwn3f"
      },
      "source": [
        "**Summary**\n",
        "The general trend still follows, it is crutial that we find the out if there is any common trait between the customers doing high high amount of transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTqwU7fQ0jkI"
      },
      "source": [
        "### transaction_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt-oFFQCrVZ0"
      },
      "outputs": [],
      "source": [
        "UVA_numeric(data,transaction_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJyehftG4qDk"
      },
      "source": [
        "**Summary**\n",
        "*    **Day_of_Year**:\n",
        "    *    most of the last transactions were made in the last 60 days of the extraction of data.\n",
        "    *    There are transactions which were made also an year ago.\n",
        "\n",
        "*   **Week_of_year and Month_of_year**: these variable validate the findings from the **day_of_year**.\n",
        "*    **Day_of_Week**: Tuesdays are often the favoured day relative to others.\n",
        "\n",
        "**Things to investigate further Down**\n",
        "*    **Customers whose last transaction was 6 months ago, did all of them churn?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tleDyj9P_j_i"
      },
      "source": [
        "## Univariate Analysis : Categorical Varibales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLWcwsoa0tlN"
      },
      "outputs": [],
      "source": [
        "data.select_dtypes(exclude=['int64','float64','Int64']).dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ebDof6Vlnq"
      },
      "source": [
        "**Grouping Varibales**\n",
        "\n",
        "* **customer_info**: gender, occupation, customer_nw_category\n",
        "* **account_info**: city, branch_code\n",
        "* **churn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i9kY6dVEITb"
      },
      "outputs": [],
      "source": [
        "# Custom function for easy visualisation of Categorical Variables\n",
        "def UVA_category(data, var_group):\n",
        "\n",
        "  '''\n",
        "  Univariate_Analysis_categorical\n",
        "  takes a group of variables (category) and plot/print all the value_counts and barplot.\n",
        "  '''\n",
        "  # setting figure_size\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,5), dpi = 100)\n",
        "\n",
        "  # for every variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    norm_count = data[i].value_counts(normalize = True)\n",
        "    n_uni = data[i].nunique()\n",
        "\n",
        "  #Plotting the variable with every information\n",
        "    plt.subplot(1,size,j+1)\n",
        "    sns.barplot(norm_count, norm_count.index , order = norm_count.index)\n",
        "    plt.xlabel('fraction/percent', fontsize = 20)\n",
        "    plt.ylabel('{}'.format(i), fontsize = 20)\n",
        "    plt.title('n_uniques = {} \\n value counts \\n {};'.format(n_uni,norm_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JowqxBPrUHOS"
      },
      "source": [
        "### customer_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXFaU9g0IY_I"
      },
      "outputs": [],
      "source": [
        "UVA_category(data, ['occupation', 'gender', 'customer_nw_category'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ato5X6wuY8vO"
      },
      "source": [
        "**Summary**\n",
        "* Occupation\n",
        "  * Majority of people are self_employed.\n",
        "  * There are extremely few Company Accounts. Might explain Outlier/Extreme values in credit/debit.\n",
        "\n",
        "* Gender:\n",
        "  *  Males accounts are 1.5 times more than Female Accounts.\n",
        "\n",
        "* customer_nw_category:\n",
        "  *  Half of all the accounts belong to the 3rd net worth category.\n",
        "  *  Less than 15% belong to the highest net worth category.\n",
        "\n",
        "**Things to investigate further down:**\n",
        "* Possibility: Company accounts are the reason behind the outlier transactions.\n",
        "* Possibility: customers belonging to the highest net worth category may explain the skewness of the transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnAMoLCkcD-b"
      },
      "source": [
        "### account_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTey5QEbY7lM"
      },
      "outputs": [],
      "source": [
        "UVA_category(data, ['city', 'branch_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTs4Ess5UE6t"
      },
      "outputs": [],
      "source": [
        "#Plotting \"city\"\n",
        "plt.figure(figsize = (5,5), dpi = 120)\n",
        "city_count = data['city'].value_counts(normalize=True)\n",
        "sns.barplot(city_count.index, city_count , order = city_count.index)\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('fraction/percent')\n",
        "plt.ylim(0,0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhNQ_I8keQ7W"
      },
      "outputs": [],
      "source": [
        "#Plotting \"branch_code\"\n",
        "plt.figure(figsize = (5,5), dpi = 120)\n",
        "branch_count = data['branch_code'].value_counts()\n",
        "sns.barplot(branch_count.index, branch_count , order = branch_count.index)\n",
        "plt.xlabel('branch_code')\n",
        "plt.ylabel('fraction/percent')\n",
        "#plt.ylim(0,0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A12aCbGWqM3l"
      },
      "source": [
        "**Summary:**\n",
        "for both variable \"city\" and \"branch_code\", there are too many categories. There is clear relation that some branches and cities are more popular with customers and and this trend decreases rapidly.\n",
        "\n",
        "**Things to investigate further Down**\n",
        "* Popular cities and branch code might be able to explain the skewness and outliers of credit/debit variables.\n",
        "* Possibility that cities and branch code with very few accounts may lead to churning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjn2DFHQ1DUA"
      },
      "source": [
        "### churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3hiwoojj5tR"
      },
      "outputs": [],
      "source": [
        "UVA_category(data, ['churn'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8SyVYHe3R2-"
      },
      "source": [
        "**Summary**\n",
        "* Number of people who churned are 1/4 times of the people who did not churn in the given data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AyX9rNl-NIZ"
      },
      "source": [
        "## Univariate: Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hbg29tD4c8G"
      },
      "outputs": [],
      "source": [
        "# finding number of missing values in every variable\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwY5XbTlevUg"
      },
      "source": [
        "**Things to investigate further down:**\n",
        "*    Gender: Do the customers with missing gender values have some common behaviour in-\n",
        "  * churn: do missing values have any relation with churn?\n",
        "\n",
        "* Dependents:\n",
        " * Missing values might be similar to zero dependents\n",
        " * churn: do missing values have any relation with churn?\n",
        "\n",
        "* Occupation:\n",
        " * Do missing values have similar behaviour to any other occupation\n",
        " * do they have some relation with churn?\n",
        "\n",
        "* city:\n",
        "  * the respective cities can be found using branch_code\n",
        "\n",
        "* last_transaction:\n",
        "  * checking their previous month and current month and previous_quarter activity might give insight on their last transaction.\n",
        "\n",
        "* For almost all the above:\n",
        "\n",
        "  * vintage: might be recording errors from same period of joining\n",
        "  * branch_code: might be recording error from certain branch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7XSk_6M8-Sn"
      },
      "source": [
        "## Univariate Analysis: Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r54EVLqQ-kbZ"
      },
      "source": [
        "**We suspected outliers in current_month and previous_month variable groups. We will verify that using bo plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBncECG3dVC2"
      },
      "outputs": [],
      "source": [
        "# custom function for easy outlier analysis\n",
        "\n",
        "def UVA_outlier(data, var_group, include_outlier = True):\n",
        "  '''\n",
        "  Univariate_Analysis_outlier:\n",
        "  takes a group of variables (INTEGER and FLOAT) and plot/print boplot and descriptives\\n\n",
        "  Runs a loop: calculate all the descriptives of i(th) variable and plot/print it \\n\\n\n",
        "\n",
        "  data : dataframe from which to plot from\\n\n",
        "  var_group : {list} type Group of Continuous variables\\n\n",
        "  include_outlier : {bool} whether to include outliers or not, default = True\\n\n",
        "  '''\n",
        "\n",
        "  size = len(var_group)\n",
        "  plt.figure(figsize = (7*size,4), dpi = 100)\n",
        "  \n",
        "  #looping for each variable\n",
        "  for j,i in enumerate(var_group):\n",
        "    \n",
        "    # calculating descriptives of variable\n",
        "    quant25 = data[i].quantile(0.25)\n",
        "    quant75 = data[i].quantile(0.75)\n",
        "    IQR = quant75 - quant25\n",
        "    med = data[i].median()\n",
        "    whis_low = quant25-(1.5*IQR)\n",
        "    whis_high = quant75+(1.5*IQR)\n",
        "\n",
        "    # Calculating Number of Outliers\n",
        "    outlier_high = len(data[i][data[i]>whis_high])\n",
        "    outlier_low = len(data[i][data[i]<whis_low])\n",
        "\n",
        "    if include_outlier == True:\n",
        "      #Plotting the variable with every information\n",
        "      plt.subplot(1,size,j+1)\n",
        "      sns.boxplot(data[i], orient=\"v\")\n",
        "      plt.ylabel('{}'.format(i))\n",
        "      plt.title('With Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n",
        "                                                                                                   round(IQR,2),\n",
        "                                                                                                   round(med,2),\n",
        "                                                                                                   (round(quant25,2),round(quant75,2)),\n",
        "                                                                                                   (outlier_low,outlier_high)\n",
        "                                                                                                   ))\n",
        "      \n",
        "    else:\n",
        "      # replacing outliers with max/min whisker\n",
        "      data2 = data[var_group][:]\n",
        "      data2[i][data2[i]>whis_high] = whis_high+1\n",
        "      data2[i][data2[i]<whis_low] = whis_low-1\n",
        "      \n",
        "      # plotting without outliers\n",
        "      plt.subplot(1,size,j+1)\n",
        "      sns.boxplot(data2[i], orient=\"v\")\n",
        "      plt.ylabel('{}'.format(i))\n",
        "      plt.title('Without Outliers\\nIQR = {}; Median = {} \\n 2nd,3rd  quartile = {};\\n Outlier (low/high) = {} \\n'.format(\n",
        "                                                                                                   round(IQR,2),\n",
        "                                                                                                   round(med,2),\n",
        "                                                                                                   (round(quant25,2),round(quant75,2)),\n",
        "                                                                                                   (outlier_low,outlier_high)\n",
        "                                                                                                   ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2slzVeVHPScG"
      },
      "source": [
        "### current_month and previous_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhhypvHgIo9q"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data, current_month,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aeCX9t2MR55"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data, current_month, include_outlier=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FXEcoBlJLlm"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data, previous_month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uILo1wPFUzFw"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data, previous_month, include_outlier=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JnOX4DxKn3Y"
      },
      "source": [
        "**Summary:**\n",
        "* If we look at corresponding plots in the outputs above, there seems to be a strong relation between the corresponding plots of previous_month and current_month variables.\n",
        "\n",
        "* Outliers are significant in number and very similar in number between corresponding plots. Which indicates some inherent undiscovered behviour of Outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqmFms6yPY7M"
      },
      "source": [
        "### previous quarters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6dxdT-2PbbU"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data,previous_quarters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWJ83i7yUiWO"
      },
      "outputs": [],
      "source": [
        "UVA_outlier(data,previous_quarters, include_outlier = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORqbv5eoQ8lK"
      },
      "source": [
        "Summary:\n",
        "* Outliers in previous two quarters are very similar but significantly large in number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqvHG14NGrcN"
      },
      "source": [
        "## Investigation directions from Univariate Analysis\n",
        "1. customer_id variable can be dropped.\n",
        "2.  Is there there any common trait/relation between the customers who are performing high transaction credit/debits?\n",
        "   * customer_nw_category might explain that.\n",
        "   * Occupation = Company might explain them\n",
        "   * popular cities might explain this\n",
        "4.  Customers whose last transaction was 6 months ago, did all of them churn? \n",
        "5. Possibility that cities and branch code with very few accounts may lead to churning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoMmh9pFGGzo"
      },
      "source": [
        "## Investigation directions from Univariate Analysis\n",
        "1. customer_id variable can be dropped.\n",
        "2.  Is there there any common trait/relation between the customers who are performing high transaction credit/debits?\n",
        "   * customer_nw_category might explain that.\n",
        "   * Occupation = Company might explain them\n",
        "   * popular cities might explain this\n",
        "4.  Customers whose last transaction was 6 months ago, did all of them churn? \n",
        "5. Possibility that cities and branch code with very few accounts may lead to churning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pLmF5hCfCnV"
      },
      "source": [
        "## Bivariate Analysis : Numerical-Numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBkKRdwlJyqB"
      },
      "outputs": [],
      "source": [
        "# isolating numerical datatypes\n",
        "numerical = data.select_dtypes(include=['int64','float64','Int64'])[:]\n",
        "numerical.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYBGrb8IqF1r"
      },
      "source": [
        "### Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBlXGiiCw09O"
      },
      "outputs": [],
      "source": [
        "# calculating correlation\n",
        "correlation = numerical.dropna().corr()\n",
        "correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5kVn205Uc4B"
      },
      "source": [
        "### Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDJHUYLEy2Gf"
      },
      "outputs": [],
      "source": [
        "# plotting heatmap usill all methods for all numerical variables\n",
        "plt.figure(figsize=(36,6), dpi=140)\n",
        "for j,i in enumerate(['pearson','kendall','spearman']):\n",
        "  plt.subplot(1,3,j+1)\n",
        "  correlation = numerical.dropna().corr(method=i)\n",
        "  sns.heatmap(correlation, linewidth = 2)\n",
        "  plt.title(i, fontsize=18)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbatuwlduSNl"
      },
      "source": [
        "* Kendall and Spearman correlation seem to have very similar pattern between them, except the slight variation in magnitude of correlation.\n",
        "*  Too many variables with insignificant correlation.\n",
        "*  Major correlation lies between the transaction variables and balance variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZSKnYzf1xg5"
      },
      "outputs": [],
      "source": [
        "# extracting transaction information of current and previous months\n",
        "var = []\n",
        "var.extend(previous_month)\n",
        "var.extend(current_month)\n",
        "var.extend(previous_quarters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZzT4v84DODe"
      },
      "outputs": [],
      "source": [
        "# plotting heatmap usill all methods for all transaction variables\n",
        "plt.figure(figsize=(36,6), dpi=140)\n",
        "for j,i in enumerate(['pearson','kendall','spearman']):\n",
        "  plt.subplot(1,3,j+1)\n",
        "  correlation = numerical[var].dropna().corr(method=i)\n",
        "  sns.heatmap(correlation, linewidth = 2)\n",
        "  plt.title(i, fontsize=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26W7HQLJS_Rz"
      },
      "source": [
        "**Inferences:**\n",
        "\n",
        "\n",
        "1.   Transaction variables like credit/debit have a strong correlation among themselves.\n",
        "2.  Balance variables have strong correlation among themselves.\n",
        "3.   Transaction variables like credit/debit have insignificant or no correlation with the Balance variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaYygjVJUf0I"
      },
      "source": [
        "### Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cirarNgU1Dn"
      },
      "outputs": [],
      "source": [
        "# Grouping variables\n",
        "transactions = ['current_month_credit','current_month_debit','previous_month_credit','previous_month_debit']\n",
        "balance = ['previous_month_end_balance','previous_month_balance','current_balance','current_month_balance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sWiCzLIGMWn"
      },
      "outputs": [],
      "source": [
        "# scatter plot for transactional variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[transactions])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izeFVmArdlcL"
      },
      "source": [
        "**the scatter plot is is not meaningful due to the presence of outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYWU6jHpeEJf"
      },
      "outputs": [],
      "source": [
        "#taking log of every value to negate outliers\n",
        "for column in var:\n",
        "  mini=1\n",
        "  if numerical[column].min()<0:\n",
        "    mini =  abs(numerical[column].min()) + 1\n",
        "  \n",
        "  numerical[column] = [i+mini for i in numerical[column]]\n",
        "  numerical[column] = numerical[column].map(lambda x : np.log(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAmHdUT8zyqG"
      },
      "outputs": [],
      "source": [
        "# scatter plot for transactional variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[transactions])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEpANup5eZwV"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the transaction variables.\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ1VkLc43tfI"
      },
      "outputs": [],
      "source": [
        "# balance variables\n",
        "plt.figure(dpi=140)\n",
        "sns.pairplot(numerical[balance])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as-bXBoFf1y5"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the balance variables.\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M0SKcLQB31s"
      },
      "outputs": [],
      "source": [
        "# previous quarters\n",
        "plt.figure(dpi=140)\n",
        "sns.scatterplot(numerical['average_monthly_balance_prevQ'], numerical['average_monthly_balance_prevQ2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL-II51yfz3F"
      },
      "source": [
        "**Inferences**\n",
        "1.    This validates the high correlation between the two previous quarters\n",
        "2.    This high correlation can be used for feature engineering during the later stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGhr2YBuLIn3"
      },
      "source": [
        "## Multivariate Analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3kEyOd8Qpye"
      },
      "source": [
        "### Pivot Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blDkoenOQpye"
      },
      "source": [
        "We are using Pivot table to comply with the objective of identifying the Churning Customers Profile using multiple categorical features.\n",
        "First, Let's use Gender, Occupation and Customer Net worth category and derive insights from the Pivot Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYkEOVbQpyf"
      },
      "source": [
        "### Gender, Occupation, Customer Net worth category with Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-4EtOlGQpyf"
      },
      "outputs": [],
      "source": [
        "data['gender'] = data['gender'].astype('object')\n",
        "data['occupation'] = data['occupation'].astype('object')\n",
        "data['customer_nw_category'] = data['customer_nw_category'].astype('object')\n",
        "data['churn'] = data['churn'].astype('int')\n",
        "data['city'] = data['city'].astype('float')\n",
        "data['branch_code'] = data['branch_code'].astype('float')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1w9K3yMQpyf"
      },
      "source": [
        "* Suitable datatype for Creating Pivot table in Pandas version (categorical datatype is not supported)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAb_1pa_Qpyf"
      },
      "outputs": [],
      "source": [
        "data.pivot_table('churn', ['gender', 'occupation'], 'customer_nw_category', aggfunc='mean')*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-5UTSJ7Qpyg"
      },
      "source": [
        "* __Highest number of churning customers__ are those __Male Customers__ who lie in __2 net worth category__ and belong to __Self-employed__ profession\n",
        "* Proportion wise for net worth category 1, Approximately 22% __Male customers__ who belong to the __Self-employed__ profession are churning\n",
        "* Proportion wise for net worth category 2, 20% __Male customers__ who belong to the __Self-employed__ profession are churning\n",
        "* For net worth category 3, Approximately 21% __Male customers__ who belong to the __Self-employed__ profession are churning\n",
        "\n",
        "* In all the cases of Customer net worth category, __Self-employed Male customers__ are more likely to churn\n",
        "\n",
        "* This would be interesting to dig deeper and find out if the __\"Self-employed Male\"__ Customers are more churning more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L93UbtRGQpyg"
      },
      "source": [
        "### Gender, Age, Occupation with Churning Status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPre4CwNQpyg"
      },
      "source": [
        "Let's use one continuous variable Age, and two categorical variables, Gender, and Occupation to derive insights related to profiles of customers who are churning.\n",
        "We will have to convert continuous variable into categorical variable for efficiently using Pivot Table. Here we are binning age into three intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZsNXhHWQpyg"
      },
      "outputs": [],
      "source": [
        "age = pd.cut(data['age'], [0, 25, 50, 100])\n",
        "data.pivot_table('churn', ['gender', age], 'occupation', aggfunc='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAqfln2ZQpyh"
      },
      "outputs": [],
      "source": [
        "age = pd.cut(data['age'], [0, 25, 50, 100])\n",
        "data.pivot_table('churn', ['gender', age], 'occupation', aggfunc='mean')*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qagUJLvmQpyh"
      },
      "source": [
        "* We have created three bins for the age variable dividing age into 3 groups 0-25, 25-50 and 50-100\n",
        "* Highest number of Customers are churning from __Male category__ who belong to the age group of __(25,50)__ and are professionally __self employed__\n",
        "* Highest Proportion of Customers are churning from __Male category__ who belong to the age group of __(0,25)__ and are professionally __self employed__\n",
        "* Here also __Self Employed Male customers__ are churning more than any other combination of categories\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn5TS6EUQpyi"
      },
      "source": [
        "### Gender,Age,Occupation and Current Balance with Churning Status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hES1A0ysQpyi"
      },
      "source": [
        "Let's dig deeper by using two continuous variables Age and Current Balance and Two Categorical Variable Gender and Occupation and try to find out the insights related to churning customers profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0TOBe4YQpyj"
      },
      "outputs": [],
      "source": [
        "balance = pd.qcut(data['current_balance'], 3)\n",
        "data.pivot_table('churn', ['gender', age], [balance, 'occupation'], aggfunc='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Fxqi62Qpyj"
      },
      "outputs": [],
      "source": [
        "balance = pd.qcut(data['current_balance'], 3)\n",
        "data.pivot_table('churn', ['gender', age], [balance, 'occupation'], aggfunc='mean')*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npwOKolvQpyk"
      },
      "source": [
        "* Current balance is divided into 3 quantiles\n",
        "* It is visible at first look that for __low current balance__ more number of customers are churning\n",
        "* For the first quantile of current balance, More than __18%__ (overall average churning) of customers are churning and for second and third quantile percentage of churning customers is less than 18%\n",
        "* In first quantile of current balance, for __self employed profession__ as the age increases for customers, their churning proportion decreases. This means that __Young Self employed Customers__ are more prone to churn \n",
        "* There is a visible gap in proportion of Self employed females who lie in the age group of (0,25) and Self employed Males who lie in the same group. __Young Male Self employed customers__ are churning more than young female self employed customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1a38yb-Qpyk"
      },
      "source": [
        "### Box Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUQMqXyyQpyk"
      },
      "source": [
        "Now in order to comply with our objective of identifying churning customers profile we will use grouped Box plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBvdaI0aQpyl"
      },
      "outputs": [],
      "source": [
        "def Grouped_Box_Plot(data, cont, cat1, cat2):\n",
        "    # boxplot\n",
        "    sns.boxplot(x=cat1, y=cont, hue=cat2, data=data, orient='v')\n",
        "    plt.title('Boxplot')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bTTtp6PQpyl"
      },
      "source": [
        "### Age, Occupation, Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEdqKByNQpyl"
      },
      "source": [
        "We are using one continuous variable Age and one categorical variable Occupation to derive insights related to churning customers profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXTI45_HQpym"
      },
      "outputs": [],
      "source": [
        "Grouped_Box_Plot(data,'age', 'occupation', 'churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZw5n9KyQpym"
      },
      "source": [
        "We can notice here that \n",
        "* For __Self-employed__ profession churning customers are slightly __younger__ than non churning customers\n",
        "* In the retired occupation for non churning customers, there are many outliers that indicate __young people who retire early are not churning__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vPiUSFPQpyn"
      },
      "source": [
        "### Vintage, Gender, Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyoL3vXdQpyn"
      },
      "source": [
        "It is also important to know the significance of vintage on churning profile of customers gender wise\n",
        "So let't take Vintage and Gender to derive insights for churning customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLClsHJgQpyn"
      },
      "outputs": [],
      "source": [
        "Grouped_Box_Plot(data,'vintage','gender', 'churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPCKjoA1Qpyn"
      },
      "source": [
        "* There is __no visible difference__ in the vintage feature for genderwise churning and non churning customers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J50s7_-vQpyo"
      },
      "source": [
        "## Pair Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZgCsObgQpyo"
      },
      "source": [
        "#### Churn vs Current & Previous month balances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Qh-FF2Qpyo"
      },
      "source": [
        "Now, we will check the relationship of the some transactional variables along with the churning status. Here conversion to log is important here as we have a lot of outliers and visualization will be difficult for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyQgThjDQpyo"
      },
      "outputs": [],
      "source": [
        "balance_cols = ['current_balance','previous_month_end_balance',\n",
        "                'current_month_balance', 'previous_month_balance']\n",
        "data1 = pd.DataFrame()\n",
        "\n",
        "for i in balance_cols:\n",
        "    data1[str('log_')+ i] = np.log(data[i] + 6000)\n",
        "\n",
        "log_balance_cols = data1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ_FTRj-Qpyp"
      },
      "outputs": [],
      "source": [
        "data1['churn'] = data['churn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQhvAvIQpyp"
      },
      "source": [
        "We will use the brilliant pairplot function from Seaborn which supports displaying relationship between multiple variables. It displays the scatter plot between a pair of feature and also displays the distribution\n",
        "\n",
        "Here I have included the following:\n",
        "* Log of current balance & previous month end balance\n",
        "* Log of average monthly balance of current and previous month\n",
        "* Churn is represented by the color here (Orange - Churn, Blue - Not Churn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHCDSwqVQpyp"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data1,vars=log_balance_cols,hue ='churn',plot_kws={'alpha':0.1})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXNANV_yQpyp"
      },
      "source": [
        "The distribution for these features look similar. We can make the following conclusions from this:\n",
        "* There is high correlation between the previous and current month balances which is expected\n",
        "* The distribution for churn and not churn is slightly different for both the cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li1WqsZSQpyp"
      },
      "source": [
        "### Credit and Debits for current and previous months\n",
        "\n",
        "Total credit and debit amounts for the current and previous can be clubbed into the same category. Let us again use the pair plot to check distributions and scatter plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUVNxQZDQpyq"
      },
      "outputs": [],
      "source": [
        "cr_dr_cols = ['current_month_credit','previous_month_credit', \n",
        "              'current_month_debit', 'previous_month_debit']\n",
        "data1 = pd.DataFrame()\n",
        "\n",
        "for i in cr_dr_cols:\n",
        "    data1[str('log_')+ i] = np.log(data[i])\n",
        "\n",
        "log_dr_cr_cols = data1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTR8IElcQpyq"
      },
      "outputs": [],
      "source": [
        "data1['churn'] = data['churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne-tlboBQpyq"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data1,vars=log_dr_cr_cols, hue = 'churn',plot_kws={'alpha':0.5})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlMsJ5EeQpyq"
      },
      "source": [
        "Both credit and debit patterns show significant difference in distributions for churned and non churned customers.\n",
        "* Bimodal distribution/Double Bell Curve shows that there are 2 different types of customers with 2 brackets of credit and debit. Now, during the modeling phase, these could be considered as a seperate set of customers\n",
        "* For debit values, we see that there is a significant difference in the distribution for churn and non churn and it might turn out to be an important feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxDUUMeQpyr"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVlbKp1EQpyr"
      },
      "outputs": [],
      "source": [
        "data_encoded = pd.get_dummies(data, drop_first=True)\n",
        "data_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6PtZKSQpyr"
      },
      "source": [
        "* Encoding the variables using get dummies pandas function so every variable has numerical value attached to it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dYZa8BhQpys"
      },
      "source": [
        "## Missing Values with Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM9iwEgFQpys"
      },
      "outputs": [],
      "source": [
        "def fill_mode(df):\n",
        "    for column in df.columns:\n",
        "        df[column].fillna(df[column].mode()[0], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGun1uZRQpys"
      },
      "outputs": [],
      "source": [
        "fill_mode(data_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eppu2xAPQpys"
      },
      "source": [
        "* Filling missing values with the mode of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f15Os-SbQpyt"
      },
      "source": [
        "### Segregating variables: Independent and Dependent Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO_KjinVQpyt"
      },
      "outputs": [],
      "source": [
        "data_encoded = data_encoded.drop('customer_id', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IX7ElW9Qpyt"
      },
      "source": [
        "* Insignification variable drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP77EDi2Qpyt"
      },
      "outputs": [],
      "source": [
        "#seperating independent and dependent variables\n",
        "x = data_encoded.drop(['churn'], axis=1)\n",
        "y = data_encoded['churn']\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfE8ouN3Qpyu"
      },
      "source": [
        "* Creating features and target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySEAHij2Qpyu"
      },
      "outputs": [],
      "source": [
        "data_encoded.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXB3kSOhQpyu"
      },
      "source": [
        "### Splitting the data into train set and the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXjaV6cnQpyv"
      },
      "outputs": [],
      "source": [
        "# Importing the train test split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x,test_x,train_y,test_y = train_test_split(x,y, random_state = 56)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MLxO6rkQpyv"
      },
      "source": [
        "* Splitting the entire data into train and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSRHE_qbQpyv"
      },
      "source": [
        "### Normalising using *min_max_scaler*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OopxW55IQpyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax-LNIz3Qpyw"
      },
      "outputs": [],
      "source": [
        "cols = train_x.columns\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS3c6Y0UQpyw"
      },
      "outputs": [],
      "source": [
        "train_x_scaled = scaler.fit_transform(train_x)\n",
        "train_x_scaled = pd.DataFrame(train_x_scaled, columns=cols)\n",
        "train_x_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws0e2TsJQpyw"
      },
      "outputs": [],
      "source": [
        "test_x_scaled = scaler.transform(test_x)\n",
        "test_x_scaled = pd.DataFrame(test_x_scaled, columns=cols)\n",
        "test_x_scaled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1PccL9xQpyx"
      },
      "source": [
        "* Scaling the data so model doesn't has bias for high valued features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLzlaMQQpyx"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjKwIVlwQpyx"
      },
      "outputs": [],
      "source": [
        "#importing Logistic Regression and metric accuracy score\n",
        "from sklearn.linear_model import LogisticRegression as LogReg\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Creating instance of Logistic Regresssion\n",
        "logreg = LogReg()\n",
        "\n",
        "# Fitting the model\n",
        "logreg.fit(train_x, train_y)\n",
        "\n",
        "# Predicting over the Train\n",
        "train_predict = logreg.predict(train_x)\n",
        "train_predict\n",
        "\n",
        "# Calculating accuracy-score\n",
        "k = accuracy_score(train_predict, train_y)\n",
        "print('Training accuracy_score', k )\n",
        "\n",
        "# Predicting over the Test Set and accuracy-score\n",
        "test_predict = logreg.predict(test_x)\n",
        "k = accuracy_score(test_predict, test_y)\n",
        "print('Test accuracy_score    ', k )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XFVYx90Qpyy"
      },
      "source": [
        "* Logistic regression works pretty well and able to provide accuracy more than 80% for both training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKzR1MNpQpyy"
      },
      "source": [
        "## Using Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FXRIrvkQpyz"
      },
      "outputs": [],
      "source": [
        "C = [10, 1, .1, .001]\n",
        "\n",
        "for c in C:\n",
        "    clf = LogReg(penalty='l1', C=c,)\n",
        "    clf.fit(train_x, train_y)\n",
        "    print('C:', c)\n",
        "    print('Coefficient of each feature:', clf.coef_)\n",
        "    print('Training accuracy:', clf.score(train_x, train_y))\n",
        "    print('Test accuracy:', clf.score(test_x, test_y))\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXzd1y-NQpyz"
      },
      "source": [
        "* As the value of C increases, Regularization constant decreases (C is inverse of Regularization Constant)\n",
        "* So most of the features associate themselves with 0 coefficient value\n",
        "* This can be a feature selection technique as well while building model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8qcMiqfQpyz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1FzYccB24irQ",
        "qfZv5qTw4rm_",
        "6PZEQUlXii1G",
        "37Pk32OwisyT",
        "TiC2VomvlWS5",
        "56ygh55Zok6v",
        "jFQ4BEyKrLkR",
        "kTqwU7fQ0jkI",
        "tleDyj9P_j_i",
        "2AyX9rNl-NIZ",
        "0pLmF5hCfCnV",
        "usLHBmuXgiKp",
        "Q85m_ybdmcb9",
        "KsyQLYV1DI4I",
        "Q2pl-Y7MNLnO",
        "Fkt2XboCPwgS",
        "RSCuzIUYec0W",
        "sSQC2-m5gct5",
        "k-Y5XxVSgg75",
        "DX4VSWJWvw-S",
        "QrfmvcvxEI_7",
        "1-hpix_pHzt5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}